# scripts\evaluate.py
"""
í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ACC, NMI, ARI ê³„ì‚° ë° í˜¼ë™ í–‰ë ¬ ìƒì„±
"""

import sys
from pathlib import Path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import os
import numpy as np
import json
from sklearn.metrics import (
    normalized_mutual_info_score,
    adjusted_rand_score,
    confusion_matrix
)
from scipy.optimize import linear_sum_assignment
import matplotlib.pyplot as plt
import seaborn as sns

from configs import load_config
from data import get_full_dataset


def calculate_accuracy(y_true, y_pred):
    """
    Hungarian algorithmìœ¼ë¡œ ìµœì  ë§¤ì¹­ í›„ accuracy ê³„ì‚°
    
    Args:
        y_true: ì‹¤ì œ ë¼ë²¨ (N,)
        y_pred: ì˜ˆì¸¡ ë¼ë²¨ (N,)
        
    Returns:
        acc: Accuracy
        best_map: ìµœì  ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
    """
    # Confusion matrix ìƒì„±
    n_clusters = max(y_pred.max(), y_true.max()) + 1
    w = np.zeros((n_clusters, n_clusters), dtype=np.int64)
    
    for i in range(y_pred.size):
        w[y_pred[i], y_true[i]] += 1
    
    # Hungarian algorithmìœ¼ë¡œ ìµœì  ë§¤ì¹­
    row_ind, col_ind = linear_sum_assignment(w.max() - w)
    
    # ë§¤ì¹­ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    best_map = {row: col for row, col in zip(row_ind, col_ind)}
    
    # ë§¤ì¹­ëœ ì˜ˆì¸¡ê°’
    y_pred_matched = np.array([best_map[pred] for pred in y_pred])
    
    # Accuracy ê³„ì‚°
    acc = np.sum(y_pred_matched == y_true) / y_true.size
    
    return acc, best_map


def plot_confusion_matrix(y_true, y_pred, title, save_path):
    """
    í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
    
    Args:
        y_true: ì‹¤ì œ ë¼ë²¨
        y_pred: ì˜ˆì¸¡ ë¼ë²¨
        title: ê·¸ë˜í”„ ì œëª©
        save_path: ì €ì¥ ê²½ë¡œ
    """
    # Hungarian algorithmìœ¼ë¡œ ìµœì  ë§¤ì¹­
    _, best_map = calculate_accuracy(y_true, y_pred)
    y_pred_matched = np.array([best_map[pred] for pred in y_pred])
    
    # Confusion matrix ê³„ì‚°
    cm = confusion_matrix(y_true, y_pred_matched)
    
    # ì‹œê°í™”
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=range(10),
        yticklabels=range(10),
        cbar_kws={'label': 'Count'}
    )
    plt.title(title, fontsize=16, pad=20)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   ğŸ’¾ ì €ì¥: {save_path}")


def evaluate_method(method_name, predictions_path, y_true, figures_dir):
    """
    íŠ¹ì • ë°©ë²•ì˜ ì„±ëŠ¥ í‰ê°€
    
    Args:
        method_name: ë°©ë²• ì´ë¦„
        predictions_path: ì˜ˆì¸¡ ê²°ê³¼ ê²½ë¡œ
        y_true: ì‹¤ì œ ë¼ë²¨
        figures_dir: ê·¸ë¦¼ ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        metrics: í‰ê°€ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {method_name} í‰ê°€")
    print(f"{'='*60}")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
    if not os.path.exists(predictions_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {predictions_path}")
        return None
    
    y_pred = np.load(predictions_path)
    print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ: {predictions_path}")
    print(f"   Shape: {y_pred.shape}")
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    acc, best_map = calculate_accuracy(y_true, y_pred)
    nmi = normalized_mutual_info_score(y_true, y_pred)
    ari = adjusted_rand_score(y_true, y_pred)
    
    print(f"\nğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
    print(f"   ACC: {acc:.4f} ({acc*100:.2f}%)")
    print(f"   NMI: {nmi:.4f}")
    print(f"   ARI: {ari:.4f}")
    
    # í´ëŸ¬ìŠ¤í„° ë¶„í¬
    print(f"\nğŸ“Š í´ëŸ¬ìŠ¤í„° ë¶„í¬:")
    unique, counts = np.unique(y_pred, return_counts=True)
    for cluster_id, count in zip(unique, counts):
        percentage = count / len(y_pred) * 100
        print(f"   Cluster {cluster_id}: {count:5d}ê°œ ({percentage:.1f}%)")
    
    # í˜¼ë™ í–‰ë ¬ ìƒì„±
    print(f"\nğŸ¨ í˜¼ë™ í–‰ë ¬ ìƒì„± ì¤‘...")
    cm_path = os.path.join(figures_dir, f'confusion_matrix_{method_name.lower().replace(" ", "_")}.png')
    plot_confusion_matrix(y_true, y_pred, f'Confusion Matrix - {method_name}', cm_path)
    
    # ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    metrics = {
        'method': method_name,
        'acc': float(acc),
        'nmi': float(nmi),
        'ari': float(ari),
        'n_samples': int(len(y_pred)),
        'cluster_distribution': {int(k): int(v) for k, v in zip(unique, counts)},
        'best_mapping': {int(k): int(v) for k, v in best_map.items()}
    }
    
    return metrics


def create_comparison_table(all_metrics, save_path):
    """
    ë¹„êµí‘œ ìƒì„± ë° ì €ì¥
    
    Args:
        all_metrics: ëª¨ë“  ë°©ë²•ì˜ ë©”íŠ¸ë¦­ ë¦¬ìŠ¤íŠ¸
        save_path: ì €ì¥ ê²½ë¡œ
    """
    print(f"\n{'='*60}")
    print("ğŸ“Š ìµœì¢… ë¹„êµí‘œ")
    print(f"{'='*60}")
    
    # í…Œì´ë¸” í—¤ë”
    print(f"\n{'ë°©ë²•':<20} {'ACC':<12} {'NMI':<12} {'ARI':<12}")
    print("-" * 60)
    
    # ê° ë°©ë²• ì¶œë ¥
    for metrics in all_metrics:
        if metrics:
            print(f"{metrics['method']:<20} "
                  f"{metrics['acc']:.4f} ({metrics['acc']*100:5.2f}%) "
                  f"{metrics['nmi']:.4f}       "
                  f"{metrics['ari']:.4f}")
    
    print("-" * 60)
    
    # ìµœê³  ì„±ëŠ¥ í‘œì‹œ
    if all_metrics:
        valid_metrics = [m for m in all_metrics if m is not None]
        if valid_metrics:
            best_acc = max(valid_metrics, key=lambda x: x['acc'])
            best_nmi = max(valid_metrics, key=lambda x: x['nmi'])
            best_ari = max(valid_metrics, key=lambda x: x['ari'])
            
            print(f"\nğŸ† ìµœê³  ì„±ëŠ¥:")
            print(f"   ACC: {best_acc['method']} ({best_acc['acc']*100:.2f}%)")
            print(f"   NMI: {best_nmi['method']} ({best_nmi['nmi']:.4f})")
            print(f"   ARI: {best_ari['method']} ({best_ari['ari']:.4f})")
    
    # JSON ì €ì¥
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(all_metrics, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")


def main():
    """ë©”ì¸ í‰ê°€ í•¨ìˆ˜"""
    
    print("\n" + "="*60)
    print("í‰ê°€ ì‹œì‘")
    print("="*60)
    
    # ============================================================
    # 1. ì„¤ì • ë¡œë“œ
    # ============================================================
    config = load_config('configs/config.yaml')
    results_dir = config['paths']['results_dir']
    figures_dir = config['paths']['figures_dir']
    
    # ============================================================
    # 2. ì‹¤ì œ ë¼ë²¨ ë¡œë“œ
    # ============================================================
    print(f"\nğŸ“‚ ë°ì´í„° ë¡œë”©...")
    _, y_true = get_full_dataset(config['data']['data_dir'])
    print(f"âœ… ì‹¤ì œ ë¼ë²¨ ë¡œë“œ ì™„ë£Œ: {y_true.shape}")
    
    # ============================================================
    # 3. ê° ë°©ë²• í‰ê°€
    # ============================================================
    all_metrics = []
    
    # Baseline K-Means
    metrics = evaluate_method(
        "Baseline K-Means",
        os.path.join(results_dir, 'baseline_predictions.npy'),
        y_true,
        figures_dir
    )
    all_metrics.append(metrics)
    
    # AE + K-Means
    metrics = evaluate_method(
        "AE + K-Means",
        os.path.join(results_dir, 'ae_kmeans_predictions.npy'),
        y_true,
        figures_dir
    )
    all_metrics.append(metrics)
    
    # IDEC (ë§ˆì§€ë§‰ epoch)
    idec_epochs = [100]  # ë˜ëŠ” [10, 50, 100] ë“± ì—¬ëŸ¬ epoch í™•ì¸
    for epoch in idec_epochs:
        idec_path = os.path.join(results_dir, f'idec_predictions_epoch{epoch}.npy')
        if os.path.exists(idec_path):
            metrics = evaluate_method(
                f"IDEC (Epoch {epoch})",
                idec_path,
                y_true,
                figures_dir
            )
            all_metrics.append(metrics)
    
    # ============================================================
    # 4. ë¹„êµí‘œ ìƒì„±
    # ============================================================
    comparison_path = os.path.join(results_dir, 'evaluation_metrics.json')
    create_comparison_table(all_metrics, comparison_path)
    
    print("\n" + "="*60)
    print("âœ… í‰ê°€ ì™„ë£Œ!")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()