# models/autoencoder.py
"""
Autoencoder ëª¨ë¸
ê³ ì°¨ì› ë°ì´í„°(784)ë¥¼ ì €ì°¨ì›(10)ìœ¼ë¡œ ì••ì¶•í–ˆë‹¤ê°€ ë‹¤ì‹œ ë³µì›
"""

import torch
import torch.nn as nn


class Autoencoder(nn.Module):
    """
    ê°„ë‹¨í•œ Autoencoder
    
    êµ¬ì¡°:
        784 â†’ 500 â†’ 500 â†’ 2000 â†’ 10 (Encoder)
        10 â†’ 2000 â†’ 500 â†’ 500 â†’ 784 (Decoder)
    """
    
    def __init__(self, input_dim=784, latent_dim=10, hidden_dims=[500, 500, 2000]):
        """
        Args:
            input_dim: ì…ë ¥ ì°¨ì› (28x28 = 784)
            latent_dim: ì••ì¶•ëœ ì°¨ì› (10)
            hidden_dims: íˆë“  ë ˆì´ì–´ í¬ê¸°ë“¤ [500, 500, 2000]
        """
        super(Autoencoder, self).__init__()
        
        self.input_dim = input_dim
        self.latent_dim = latent_dim
        
        # ============================================================
        # Encoder: 784 â†’ 10ìœ¼ë¡œ ì••ì¶•
        # ============================================================
        encoder_layers = []
        
        # ì²« ë²ˆì§¸ ë ˆì´ì–´: 784 â†’ 500
        encoder_layers.append(nn.Linear(input_dim, hidden_dims[0]))
        encoder_layers.append(nn.ReLU())
        
        # ì¤‘ê°„ ë ˆì´ì–´ë“¤: 500 â†’ 500 â†’ 2000
        for i in range(len(hidden_dims) - 1):
            encoder_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))
            encoder_layers.append(nn.ReLU())
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´: 2000 â†’ 10
        encoder_layers.append(nn.Linear(hidden_dims[-1], latent_dim))
        
        self.encoder = nn.Sequential(*encoder_layers)
        
        # ============================================================
        # Decoder: 10 â†’ 784ë¡œ ë³µì›
        # ============================================================
        decoder_layers = []
        
        # ì²« ë²ˆì§¸ ë ˆì´ì–´: 10 â†’ 2000
        decoder_layers.append(nn.Linear(latent_dim, hidden_dims[-1]))
        decoder_layers.append(nn.ReLU())
        
        # ì¤‘ê°„ ë ˆì´ì–´ë“¤: 2000 â†’ 500 â†’ 500
        for i in range(len(hidden_dims) - 1, 0, -1):
            decoder_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i-1]))
            decoder_layers.append(nn.ReLU())
        
        # ë§ˆì§€ë§‰ ë ˆì´ì–´: 500 â†’ 784
        decoder_layers.append(nn.Linear(hidden_dims[0], input_dim))
        decoder_layers.append(nn.Sigmoid())  # 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ
        
        self.decoder = nn.Sequential(*decoder_layers)
    
    def forward(self, x):
        """
        ìˆœì „íŒŒ
        
        Args:
            x: ì…ë ¥ ì´ë¯¸ì§€ (batch_size, 784)
            
        Returns:
            ë³µì›ëœ ì´ë¯¸ì§€ (batch_size, 784)
        """
        z = self.encoder(x)      # ì••ì¶•
        x_recon = self.decoder(z)  # ë³µì›
        return x_recon
    
    def encode(self, x):
        """
        ì¸ì½”ë”©ë§Œ ìˆ˜í–‰ (ì••ì¶•ë§Œ)
        
        Args:
            x: ì…ë ¥ ì´ë¯¸ì§€ (batch_size, 784)
            
        Returns:
            ì••ì¶•ëœ ë²¡í„° z (batch_size, 10)
        """
        return self.encoder(x)
    
    def decode(self, z):
        """
        ë””ì½”ë”©ë§Œ ìˆ˜í–‰ (ë³µì›ë§Œ)
        
        Args:
            z: ì••ì¶•ëœ ë²¡í„° (batch_size, 10)
            
        Returns:
            ë³µì›ëœ ì´ë¯¸ì§€ (batch_size, 784)
        """
        return self.decoder(z)


# ============================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================================
if __name__ == "__main__":
    print("="*60)
    print("Autoencoder ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # 1. ëª¨ë¸ ìƒì„±
    model = Autoencoder(input_dim=784, latent_dim=10)
    print(f"\nâœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    print(f"   ì…ë ¥ ì°¨ì›: 784")
    print(f"   ì ì¬ ì°¨ì›: 10")
    
    # 2. ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
    print(f"\nğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜:")
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
    
    # 3. ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
    batch_size = 32
    x = torch.randn(batch_size, 784)  # ëœë¤ ì…ë ¥
    
    print(f"\nğŸ”„ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸:")
    print(f"   ì…ë ¥ shape: {x.shape}")
    
    # ì „ì²´ ê³¼ì • (ì••ì¶• + ë³µì›)
    x_recon = model(x)
    print(f"   ì¶œë ¥ shape: {x_recon.shape}")
    
    # ì••ì¶•ë§Œ
    z = model.encode(x)
    print(f"   ì ì¬ë²¡í„° shape: {z.shape}")
    
    # 4. ë³µì› ì˜¤ì°¨ í™•ì¸
    mse = torch.mean((x - x_recon) ** 2)
    print(f"\nğŸ“‰ ì´ˆê¸° ë³µì› ì˜¤ì°¨ (MSE): {mse.item():.4f}")
    print(f"   (í•™ìŠµ ì „ì´ë¼ ì˜¤ì°¨ê°€ í½ë‹ˆë‹¤)")
    
    print("\n" + "="*60)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
    print("="*60)