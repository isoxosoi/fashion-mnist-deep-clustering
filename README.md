# Fashion-MNIST Deep Clustering Project

ì´ í”„ë¡œì íŠ¸ëŠ” Fashion-MNIST ë°ì´í„°ì…‹ì— ëŒ€í•´ 3ê°€ì§€ í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•(Baseline K-Means, AE + K-Means, IDEC)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ Deep Clusteringì˜ ìš°ìˆ˜ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
- Unsupervised Learningì„ í†µí•œ ì´ë¯¸ì§€ í´ëŸ¬ìŠ¤í„°ë§
- ì „í†µì  ë°©ë²•(K-Means) vs Deep Learning ë°©ë²•(IDEC) ë¹„êµ
- End-to-end í•™ìŠµì˜ íš¨ê³¼ ê²€ì¦

### ë°ì´í„°ì…‹
- **Fashion-MNIST**: 60,000 train + 10,000 test ì´ë¯¸ì§€
- **ì´ë¯¸ì§€ í¬ê¸°**: 28Ã—28 grayscale
- **í´ë˜ìŠ¤ ìˆ˜**: 10 (ì˜ë¥˜ ì¹´í…Œê³ ë¦¬)

---

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°
```
fashion-mnist-clustering/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.yaml              # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
â”œâ”€â”€ data/
â”‚   â””â”€â”€ __init__.py              # ë°ì´í„° ë¡œë”
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ autoencoder.py           # Autoencoder ì •ì˜
â”‚   â””â”€â”€ idec.py                  # IDEC ì •ì˜
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_baseline.py        # 1. Baseline K-Means
â”‚   â”œâ”€â”€ train_autoencoder.py     # 2. Autoencoder ì‚¬ì „í•™ìŠµ
â”‚   â”œâ”€â”€ train_ae_kmeans.py       # 3. AE + K-Means
â”‚   â”œâ”€â”€ train_idec.py            # 4. IDEC í•™ìŠµ
â”‚   â”œâ”€â”€ evaluate.py              # 5. í‰ê°€ (ACC, NMI, ARI)
â”‚   â””â”€â”€ visualize.py             # 6. ì‹œê°í™” (t-SNE, í•™ìŠµ ê³¡ì„ )
â”œâ”€â”€ results/                     # ê²°ê³¼ ì €ì¥ (ìë™ ìƒì„±)
â”‚   â”œâ”€â”€ checkpoints/             # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ figures/                 # ì‹œê°í™” ê²°ê³¼
â”‚   â””â”€â”€ *.npy, *.json            # ì˜ˆì¸¡ ë° ë©”íƒ€ ë°ì´í„°
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“Š ì£¼ìš” ê²°ê³¼

### ì„±ëŠ¥ ë¹„êµ

| Method | Accuracy (ACC) | NMI | ARI | Improvement |
|--------|----------------|-----|-----|-------------|
| Baseline K-Means | 47.38% | 0.5118 | 0.3479 | - |
| AE + K-Means | 56.70% | 0.5670 | 0.3952 | **+9.32%p** |
| **IDEC (Epoch 100)** | **62.87%** â­ | **0.6465** | **0.5037** | **+6.17%p** |

**ì´ ê°œì„ ìœ¨: 47.38% â†’ 62.87% (+15.49%p)**

### ê³„ì‚° íš¨ìœ¨ì„± vs ì„±ëŠ¥ Trade-off

| Method | í•™ìŠµ ì‹œê°„ | ì¶”ë¡  ì‹œê°„ | Inertia | Accuracy | ë¹„ê³  |
|--------|----------|----------|---------|----------|------|
| Baseline K-Means | 127.8ì´ˆ | - | 1,906,648.75 | 47.38% | âš¡ ë¹ ë¥´ì§€ë§Œ ë‚®ì€ ì„±ëŠ¥ |
| AE + K-Means | 9.8ì´ˆ* | ~0.01ì´ˆ/1K | 388,679.625 | 56.70% | âš–ï¸ ë¹ ë¥´ê³  ì¤€ìˆ˜í•œ ì„±ëŠ¥ |
| **IDEC** | **~60ë¶„** | **~0.01ì´ˆ/1K** | **-** | **62.87%** | **ğŸ† ìµœê³  ì„±ëŠ¥** |

*AE ì‚¬ì „í•™ìŠµ ì‹œê°„(~30ë¶„) ì œì™¸, K-Meansë§Œ ì¸¡ì •

**í•µì‹¬ í¬ì¸íŠ¸:**
- **Inertia ê°ì†Œ**: 1,906,648.75 â†’ 388,679.625 (**79.6% â†“**, ì°¨ì› ì¶•ì†Œ íš¨ê³¼)
- **ê³„ì‚° ì†ë„**: 127.8ì´ˆ â†’ 9.8ì´ˆ (**13ë°° ë¹ ë¦„**, AE + K-Means)
- **IDECì˜ ê°•ì **: í•™ìŠµì€ ê¸¸ì§€ë§Œ(**~60ë¶„**) í•œ ë²ˆ í•™ìŠµ í›„ **ì‹¤ì‹œê°„ ì¶”ë¡  ê°€ëŠ¥**

**IDECì˜ ì‹¤ìš©ì„±:**
- âœ… **ì¼íšŒì„± í•™ìŠµ**: í•œ ë²ˆ í•™ìŠµ í›„ ëª¨ë¸ ì˜êµ¬ ì¬ì‚¬ìš©
- âœ… **ë¹ ë¥¸ ì¶”ë¡ **: ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì‹¤ì‹œê°„ í´ëŸ¬ìŠ¤í„°ë§ (~0.01ì´ˆ/1K)
- âœ… **í”„ë¡œë•ì…˜ ì¤€ë¹„**: í•™ìŠµ íˆ¬ì ëŒ€ë¹„ ìµœê³  ì„±ëŠ¥ ë³´ì¥

### ì£¼ìš” ì¸ì‚¬ì´íŠ¸

1. **IDECì˜ ì••ë„ì  ìš°ìˆ˜ì„±** â­
   - ëª¨ë“  ì§€í‘œ(ACC, NMI, ARI)ì—ì„œ **ìµœê³  ì„±ëŠ¥** ë‹¬ì„±
   - Baseline ëŒ€ë¹„ **+15.49%p**, AE + K-Means ëŒ€ë¹„ **+6.17%p** í–¥ìƒ
   - **End-to-end ìµœì í™”**ë¡œ clusteringì— ê°€ì¥ ì í•©í•œ representation í•™ìŠµ

2. **ì°¨ì› ì¶•ì†Œì˜ íš¨ê³¼**
   - 784ì°¨ì› â†’ 10ì°¨ì› ì¶•ì†Œë¡œ Inertia **79.6% ê°ì†Œ**
   - ê³„ì‚° ì†ë„ **13ë°° í–¥ìƒ** (127.8ì´ˆ â†’ 9.8ì´ˆ)
   - ê³ ì°¨ì›ì˜ ì €ì£¼(Curse of Dimensionality) ê·¹ë³µ

3. **Joint Optimizationì˜ í•µì‹¬ ê°€ì¹˜**
   - Two-stage ë°©ë²• (AE + K-Means) ëŒ€ë¹„ **+6.17%p** í–¥ìƒ
   - ë³µì›ê³¼ í´ëŸ¬ìŠ¤í„°ë§ì„ **ë™ì‹œ ìµœì í™”**í•˜ì—¬ ë” ë‚˜ì€ representation í•™ìŠµ
   - Self-training ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•œ ì§€ì†ì  ê°œì„ 

4. **í•™ìŠµ ì‹œê°„ vs ì„±ëŠ¥ Trade-off**
   - IDECëŠ” í•™ìŠµ ì‹œê°„ì´ ê¸¸ì§€ë§Œ(**~60ë¶„**), **ì••ë„ì  ì„±ëŠ¥**ìœ¼ë¡œ íˆ¬ì ê°€ì¹˜ ì¶©ë¶„
   - í•œ ë²ˆ í•™ìŠµ í›„ **ì˜êµ¬ ì¬ì‚¬ìš©** ê°€ëŠ¥ (ì¶”ë¡  ì‹œê°„ ~0.01ì´ˆ/1K)
   - **í”„ë¡œë•ì…˜ í™˜ê²½ì— ìµœì **: ë°°í¬ í›„ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ê°€ëŠ¥

5. **ì‹¤í—˜ ì¬í˜„ì„±**
   - ëª¨ë“  ì‹¤í—˜ì€ `seed=42`ë¡œ ê³ ì •
   - ê²°ê³¼ëŠ” `results/evaluation_metrics.json`ì— ì €ì¥ë¨

### ì‹œê°í™” ê²°ê³¼
<img width="5370" height="1674" alt="Image" src="https://github.com/user-attachments/assets/92396e69-5181-40ff-9753-60e161a02423" />

**í´ëŸ¬ìŠ¤í„° ë¶„ë¦¬ë„ ë¹„êµ:**
- **Baseline K-Means**: í´ëŸ¬ìŠ¤í„°ê°€ ì‹¬í•˜ê²Œ ê²¹ì¹¨ (ê³ ì°¨ì› ê³µê°„ì˜ í•œê³„)
- **AE + K-Means**: í´ëŸ¬ìŠ¤í„°ê°€ ë¶„ë¦¬ë˜ê¸° ì‹œì‘ (íš¨ê³¼ì ì¸ ì°¨ì› ì¶•ì†Œ)
- **IDEC**: í´ëŸ¬ìŠ¤í„°ê°€ **ëª…í™•íˆ ë¶„ë¦¬ë¨** (ìµœì í™”ëœ representation) â­

**IDECì˜ ì‹œê°ì  ìš°ìˆ˜ì„±:**
- âœ¨ í´ëŸ¬ìŠ¤í„° ê°„ ëšœë ·í•œ ê²½ê³„
- âœ¨ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ë†’ì€ ë°€ì§‘ë„
- âœ¨ Overlapping ê±°ì˜ ì œë¡œ

---

## ğŸ“š ê¸°ìˆ  ìŠ¤íƒ

- **Python 3.12**
- **PyTorch 2.0+**: ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- **Scikit-learn**: K-Means, í‰ê°€ ë©”íŠ¸ë¦­
- **NumPy, Pandas**: ë°ì´í„° ì²˜ë¦¬
- **Matplotlib, Seaborn**: ì‹œê°í™”

---

## ğŸ“– ì°¸ê³  ë¬¸í—Œ

1. Xie, J., et al. (2016). "Unsupervised Deep Embedding for Clustering Analysis." ICML.
2. Guo, X., et al. (2017). "Improved Deep Embedded Clustering with Local Structure Preservation." IJCAI.
3. Xiao, H., et al. (2017). "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms."

---

## ğŸ‘¥ ì‘ì„±ì

- **ê³¼ëª©**: ì¸ê³µì§€ëŠ¥ì‘ìš©
- **í”„ë¡œì íŠ¸**: Deep Clustering on Fashion-MNIST
